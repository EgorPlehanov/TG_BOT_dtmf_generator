import numpy as np
import sounddevice as sd
from scipy.io import wavfile
from pydub import AudioSegment
from io import BytesIO
import os
from typing import Optional, List
from scipy.signal import butter, lfilter
import matplotlib.pyplot as plt

from plotter import plot_dtmf_analysis_results


class DTMF:
    def __init__(
        self,
        duration = 0.1,                 # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞
        silence_duration = 0.05,        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–∏–≥–Ω–∞–ª–∞–º–∏
        sampling_rate = 16000,          # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        A = 0.5,                        # –ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∏–≥–Ω–∞–ª–∞
        decode_fragments_duration = 150 # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    ):
        self.duration = duration
        self.silence_duration = silence_duration
        self.sampling_rate = sampling_rate
        self.A = A
        self.decode_fragments_duration = decode_fragments_duration
        
        self.symbols = ['1', '2', '3', 'A', '4', '5', '6', 'B', '7', '8', '9', 'C', '*', '0', '#', 'D']
        self.frequencies = [697, 770, 852, 941, 1209, 1336, 1477, 1633]
        self.low_frequencies = self.frequencies[:4]
        self.high_frequencies = self.frequencies[4:]
        
        self.symbols_to_frequencies = {
            symbol: (self.low_frequencies[index // 4], self.high_frequencies[index % 4])
            for index, symbol in enumerate(self.symbols)
        }
        self.frequencies_to_symbols = {
            frequencies: symbol
            for symbol, frequencies in self.symbols_to_frequencies.items()
        }


    def set_parameter(self, parameter_name: str, parameter_value: [int, float]) -> None:
        '''–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –≤ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ'''
        setattr(self, parameter_name, parameter_value)

    
    def get_parameters(self) -> dict:
        '''–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ DTMF'''
        return {
            'duration': {
                'name': '‚åõ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞',
                'unit': '—Å–µ–∫—É–Ω–¥',
                'value': self.duration,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            },
            'silence_duration': {
                'name': '‚åö –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Å–∏–≥–Ω–∞–ª–∞–º–∏',
                'unit': '—Å–µ–∫—É–Ω–¥',
                'value': self.silence_duration,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            },
            'sampling_rate': {
                'name': ' üé∂ –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏',
                'unit': '–ì—Ü',
                'value': self.sampling_rate,
                'validator': lambda x: isinstance(x, (int, float)) and x > 0,
                'converter': lambda x: int(x)
            },
            'A': {
                'name': ' üîä –ê–º–ø–ª–∏—Ç—É–¥–∞ —Å–∏–≥–Ω–∞–ª–∞',
                'value': self.A,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            },
            'decode_fragments_duration': {
                'name': ' ‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è',
                'unit': '–º—Å',
                'value': self.decode_fragments_duration,
                'validator': lambda x: isinstance(x, (int, float)) and x > 0,
                'converter': lambda x: int(x)
            }
        }
    

    def _play_dtmf_tone(self,
        signal: Optional[np.ndarray] = None,
        number: Optional[str] = None,
        file_path: Optional[str] = None
    ) -> None:
        '''–ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª DTMF'''
        if signal is None:
            if number is not None:
                signal = self.generate_dtmf_tone(number)
            elif file_path is not None:
                with open(file_path, 'rb') as f:
                    signal = np.frombuffer(f.read(), dtype=np.int16)
            return
                
        sd.play(signal, self.sampling_rate)
        sd.wait()


    def _save_dtmf_to_wav(self,
        filename: str = "dtmf",
        signal: Optional[np.ndarray] = None,
        number: Optional[str] = None
    ) -> str:
        '''–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª DTMF –≤ —Ñ–æ—Ä–º–∞—Ç–µ wav'''
        if signal is None:
            if number is not None:
                signal = self.generate_dtmf_tone(number)
            return
        
        output_path = os.path.join("src\\audio", f"{filename}.wav")
        wavfile.write(output_path, self.sampling_rate, signal)

        return output_path


    def generate_dtmf_tone(self, phone_number: str) -> np.ndarray:
        '''–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª DTMF'''
        t = np.linspace(0, self.duration, int(self.sampling_rate * self.duration), endpoint=False)

        dtmf_signal = []
        for digit in phone_number:
            f1, f2 = self.symbols_to_frequencies[digit]

            signal_1 = self.A * np.sin(2 * np.pi * f1 * t)
            signal_2 = self.A * np.sin(2 * np.pi * f2 * t)
            dtmf_signal.extend(signal_1 + signal_2)

            silence = np.zeros(int(self.silence_duration * self.sampling_rate))
            dtmf_signal.extend(silence)

        # Normalize the signal to [-32767, 32767] and convert it to 16-bit integer
        dtmf_signal = np.int16(dtmf_signal / np.max(np.abs(dtmf_signal)) * 32767)

        return dtmf_signal


    def get_dtmf_signal_file(self, number: str, format: str = "wav") -> tuple:
        '''–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª DTMF –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ wav –∏–ª–∏ mp3'''
        signal = self.generate_dtmf_tone(number)

        # file_path = self._save_dtmf_to_wav(number, signal) # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ wav
        # self._play_dtmf_tone(file_path=file_path) # –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª

        if format == "wav":
            return signal, "wav"
        elif format == "mp3":
            audio = AudioSegment(signal.tobytes(), frame_rate=self.sampling_rate, sample_width=2, channels=1)
            output = BytesIO()
            audio.export(output, format="mp3")
            return output.getvalue(), "mp3"
        else:
            raise ValueError("Unsupported format")
        

    def recognize_dtmf(self, audio_data, file_format=None) -> tuple:
        '''–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ DTMF'''
        audio = AudioSegment.from_file(BytesIO(audio_data), format=file_format)
        signal = np.array(audio.get_array_of_samples())
        sampling_rate = audio.frame_rate

        # filtered_signal = self.frequency_filter(signal, sampling_rate, self.frequencies)
        
        symbols, frequencies = self.decode_dtmf(signal, sampling_rate)
        graphs_images = plot_dtmf_analysis_results(signal, sampling_rate, frequencies, symbols)
        
        return ''.join(symbols), graphs_images
    

    def goertzel(self, samples, frequency, sample_rate):
        '''–ê–ª–≥–æ—Ä–∏—Ç–º –ì—ë—Ä—Ü–µ–ª—è'''
        sample_length = len(samples)

        coeff = 2 * np.cos(2 * np.pi * frequency / sample_rate)
        prev_1, prev_2 = 0, 0

        for n in range(sample_length):
            curr = samples[n] + coeff * prev_1 - prev_2
            prev_2 = prev_1
            prev_1 = curr
        
        return np.sqrt(curr**2 + prev_1**2)


    def decode_dtmf(self, audio_data, sample_rate):
        '''–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ DTMF'''
        decoded_numbers = []     # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        decoded_frequencies = [] # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã

        audio_data = audio_data / 32767 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω–∞–ª–∞

        chunks = self.get_chanks(audio_data, sample_rate)
        print('chunks', chunks)

        for start, end in chunks:
            chunk = audio_data[start:end]
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∏–∑–∫–∏—Ö —á–∞—Å—Ç–æ—Ç –≤ —Å—ç–º–ø–ª–µ —Å–∏–≥–Ω–∞–ª–∞
            dtmf_low_freq_scores = [0] * len(self.low_frequencies)
            for freq_index, freq in enumerate(self.low_frequencies):
                dtmf_low_freq_scores[freq_index] = self.goertzel(chunk, freq, sample_rate)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç –≤ —Å—ç–º–ø–ª–µ —Å–∏–≥–Ω–∞–ª–∞
            dtmf_high_freq_scores = [0] * len(self.high_frequencies)
            for freq_index, freq in enumerate(self.high_frequencies):
                dtmf_high_freq_scores[freq_index] = self.goertzel(chunk, freq, sample_rate)

            low_freq_index = dtmf_low_freq_scores.index(max(dtmf_low_freq_scores))
            high_freq_index = dtmf_high_freq_scores.index(max(dtmf_high_freq_scores))

            low_freq = self.low_frequencies[low_freq_index]
            high_freq = self.high_frequencies[high_freq_index]

            decoded_numbers.append(self.frequencies_to_symbols[(low_freq, high_freq)])

            decoded_frequencies.append({
                'symbol': self.frequencies_to_symbols[(low_freq, high_freq)],
                'low_frequency': low_freq,
                'high_frequency': high_freq,
                'position_start': start,
                'position_end': end
            })

        return decoded_numbers, decoded_frequencies
    

    def get_chanks(self, audio_data, sample_rate) -> List[tuple]:
        '''–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã'''
        freq_filtered_signal = self.filter_signal_by_frequencies(audio_data, sample_rate, self.frequencies)
        amp_threshold = self.calculate_amplitude_threshold(freq_filtered_signal)
        amp_filtered_signal = self.amplitude_filter(freq_filtered_signal, amp_threshold)
        window_size = int(sample_rate * 20 / 1000)
        signal_energy = self.calculate_energy(amp_filtered_signal, window_size)
        chunks = self.get_energy_intervals(signal_energy)
        return chunks
    

    def calculate_offset(self, center_frequency: float | int) -> int:
        '''–í—ã—á–∏—Å–ª—è–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã'''
        if center_frequency >= 300 and center_frequency < 1000:
            return 20
        elif center_frequency >= 1000 and center_frequency < 3000:
            return 50
        elif center_frequency >= 3000 and center_frequency < 10000:
            return 200
        return 0


    def butter_bandpass_filter(
        self,
        signal: np.ndarray,
        center_frequency: float,
        sample_rate: float,
        order: int = 4
    ) -> np.ndarray:
        '''–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ–ª–æ—Å–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞ –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Å–∏–≥–Ω–∞–ª—É'''
        nyquist = 0.5 * sample_rate
        offset = self.calculate_offset(center_frequency)
        low = (center_frequency - offset) / nyquist
        high = (center_frequency + offset) / nyquist
        b, a = butter(order, [low, high], btype='band')
        y = lfilter(b, a, signal)
        return y


    def filter_signal_by_frequencies(
        self,
        signal: np.ndarray,
        sample_rate: int,
        frequencies: List[float],
    ) -> np.ndarray:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —á–∞—Å—Ç–æ—Ç–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ–∏–ª—å—Ç—Ä–∞ –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞-–ø–æ–ª–æ—Å—ã"""
        filtered_signal = np.sum([self.butter_bandpass_filter(signal, freq, sample_rate) for freq in frequencies], axis=0)
        return filtered_signal


    def calculate_amplitude_threshold(self, signal, multiplier=1.0):
        mean_amplitude = np.mean(np.abs(signal))
        std_amplitude = np.std(np.abs(signal))
        threshold = mean_amplitude + multiplier * std_amplitude
        return threshold


    def amplitude_filter(self, signal, threshold):
        filtered_signal = np.where(np.abs(signal) > threshold, signal, 0)
        return filtered_signal
    
    def calculate_energy(self, signal, window_size):
        squared_signal = np.square(signal)
        energy = np.convolve(squared_signal, np.ones(window_size)/window_size, mode='valid')
        return energy
    

    def get_energy_intervals(self, energy_values):
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, –≥–¥–µ —ç–Ω–µ—Ä–≥–∏—è —Å–∏–≥–Ω–∞–ª–∞ –±–æ–ª—å—à–µ 0."""
        intervals = []
        start_index = None

        for i, energy in enumerate(energy_values):
            if energy > 0:
                if start_index is None:
                    start_index = i
            elif start_index is not None:
                intervals.append((start_index, i - 1))
                start_index = None

        if start_index is not None:
            intervals.append((start_index, len(energy_values) - 1))

        return intervals



if __name__ == '__main__':
    dtmf = DTMF(sampling_rate=8000)

    phone_number = "1122"
    signal = dtmf.generate_dtmf_tone(phone_number)
    print(signal)

    result = dtmf.decode_dtmf(signal)
    print(result)