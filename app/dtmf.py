import numpy as np
import sounddevice as sd
from scipy.io import wavfile
from pydub import AudioSegment
from io import BytesIO
import os
from typing import Optional, List
from scipy.signal import butter, lfilter

from plotter import plot_dtmf_analysis_results


class DTMF:
    _NORMALIZATION_FACTOR = 32767
    _WINDOW_SIZE_MS = 20

    def __init__(
        self,
        duration = 0.1,                 # Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        silence_duration = 0.05,        # Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ð°ÑƒÐ·Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ¸Ð³Ð½Ð°Ð»Ð°Ð¼Ð¸
        sampling_rate = 16000,          # Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° Ð´Ð¸ÑÐºÑ€ÐµÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        A = 0.5                         # ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð° ÑÐ¸Ð³Ð½Ð°Ð»Ð°
    ):
        self.duration = duration
        self.silence_duration = silence_duration
        self.sampling_rate = sampling_rate
        self.A = A
        
        self.symbols = ['1', '2', '3', 'A', '4', '5', '6', 'B', '7', '8', '9', 'C', '*', '0', '#', 'D']
        self.frequencies = [697, 770, 852, 941, 1209, 1336, 1477, 1633]
        self.low_frequencies = self.frequencies[:4]
        self.high_frequencies = self.frequencies[4:]
        
        self.symbols_to_frequencies = {
            symbol: (self.low_frequencies[index // 4], self.high_frequencies[index % 4])
            for index, symbol in enumerate(self.symbols)
        }
        self.frequencies_to_symbols = {
            frequencies: symbol
            for symbol, frequencies in self.symbols_to_frequencies.items()
        }


    def set_parameter(self, parameter_name: str, parameter_value: [int, float]) -> None:
        '''Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ Ð² Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ'''
        setattr(self, parameter_name, parameter_value)

    
    def get_parameters(self) -> dict:
        '''Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ DTMF'''
        return {
            'duration': {
                'name': 'âŒ› Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐ¸Ð³Ð½Ð°Ð»Ð°',
                'unit': 'ÑÐµÐºÑƒÐ½Ð´',
                'value': self.duration,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            },
            'silence_duration': {
                'name': 'âŒš Ð˜Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ¸Ð³Ð½Ð°Ð»Ð°Ð¼Ð¸',
                'unit': 'ÑÐµÐºÑƒÐ½Ð´',
                'value': self.silence_duration,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            },
            'sampling_rate': {
                'name': ' ðŸŽ¶ Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° Ð´Ð¸ÑÐºÑ€ÐµÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸',
                'unit': 'Ð“Ñ†',
                'value': self.sampling_rate,
                'validator': lambda x: isinstance(x, (int, float)) and x > 0,
                'converter': lambda x: int(x)
            },
            'A': {
                'name': ' ðŸ”Š ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð° ÑÐ¸Ð³Ð½Ð°Ð»Ð°',
                'value': self.A,
                'validator': lambda x: isinstance(x, (int, float)) and x >= 0,
                'converter': lambda x: float(x)
            }
        }
    

    def play_dtmf_tone(self,
        signal: Optional[np.ndarray] = None,
        number: Optional[str] = None,
        file_path: Optional[str] = None
    ) -> None:
        '''ÐŸÑ€Ð¾Ð¸Ð³Ñ€Ñ‹Ð²Ð°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¸Ð³Ð½Ð°Ð» DTMF'''
        if signal is None:
            if number is not None:
                signal = self.generate_dtmf_tone(number)
            elif file_path is not None:
                with open(file_path, 'rb') as f:
                    signal = np.frombuffer(f.read(), dtype=np.int16)
            return
                
        sd.play(signal, self.sampling_rate)
        sd.wait()


    def save_dtmf_to_wav(self,
        filename: str = "dtmf",
        signal: Optional[np.ndarray] = None,
        number: Optional[str] = None
    ) -> str:
        '''Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¸Ð³Ð½Ð°Ð» DTMF Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ wav'''
        if signal is None:
            if number is not None:
                signal = self.generate_dtmf_tone(number)
            return
        
        output_path = os.path.join("src\\audio", f"{filename}.wav")
        wavfile.write(output_path, self.sampling_rate, signal)

        return output_path


    def generate_dtmf_tone(self, phone_number: str) -> np.ndarray:
        '''Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¸Ð³Ð½Ð°Ð» DTMF'''
        t = np.linspace(0, self.duration, int(self.sampling_rate * self.duration), endpoint=False)

        dtmf_signals = [
            self.A * (np.sin(2 * np.pi * f1 * t) + np.sin(2 * np.pi * f2 * t))
            for digit in phone_number
            for f1, f2 in [self.symbols_to_frequencies[digit]]
        ]

        silence_duration_samples = int(self.silence_duration * self.sampling_rate)
        silence = np.zeros(silence_duration_samples)

        dtmf_signals_with_silence = np.concatenate([
            value
            for signal_silence in zip(dtmf_signals, [silence] * len(dtmf_signals))
            for value in signal_silence
        ][:-1])

        # Normalize the signal to [-32767, 32767] and convert it to 16-bit integer
        return np.int16(dtmf_signals_with_silence / np.max(np.abs(dtmf_signals_with_silence)) * self._NORMALIZATION_FACTOR)


    def get_dtmf_signal_file(self, number: str, format: str = "wav") -> tuple:
        '''Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¸Ð³Ð½Ð°Ð» DTMF Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐµÐ³Ð¾ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ wav Ð¸Ð»Ð¸ mp3'''
        signal = self.generate_dtmf_tone(number)

        # file_path = self._save_dtmf_to_wav(number, signal) # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐ¸Ð³Ð½Ð°Ð» Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ wav
        # self._play_dtmf_tone(file_path=file_path) # ÐŸÑ€Ð¾Ð¸Ð³Ñ€Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¸Ð³Ð½Ð°Ð»

        if format == "wav":
            return signal, "wav"
        elif format == "mp3":
            audio = AudioSegment(signal.tobytes(), frame_rate=self.sampling_rate, sample_width=2, channels=1)
            output = BytesIO()
            audio.export(output, format="mp3")
            return output.getvalue(), "mp3"
        else:
            raise ValueError("Unsupported format")
        

    def recognize_dtmf(self, audio_data: bytes, file_format: str = None) -> tuple:
        '''Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ð° DTMF'''
        audio = AudioSegment.from_file(BytesIO(audio_data), format=file_format)
        signal = np.array(audio.get_array_of_samples())
        sampling_rate = audio.frame_rate

        symbols, frequencies = self._decode_dtmf(signal, sampling_rate)
        graphs_images = plot_dtmf_analysis_results(signal, sampling_rate, frequencies, symbols)
        
        return ''.join(symbols), graphs_images
    

    def _goertzel(self, samples: np.ndarray, frequency: int | float, sample_rate: int) -> float:
        '''ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ð“Ñ‘Ñ€Ñ†ÐµÐ»Ñ'''
        sample_length = len(samples)

        coeff = 2 * np.cos(2 * np.pi * frequency / sample_rate)
        prev_1, prev_2 = 0, 0

        for n in range(sample_length):
            curr = samples[n] + coeff * prev_1 - prev_2
            prev_2 = prev_1
            prev_1 = curr
        
        return np.sqrt(curr**2 + prev_1**2)


    def _decode_dtmf(self, audio_data: np.ndarray, sample_rate: int) -> tuple:
        '''Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ð° DTMF'''
        decoded_numbers = []     # Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹
        decoded_frequencies = [] # Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹

        audio_data = audio_data / max(abs(audio_data)) # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¸Ð½Ð°Ð»Ð°

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾Ð±Ð»Ð°ÑÑ‚ÐµÐ¹ Ð´Ð»Ñ Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        chunks = self._get_chanks(audio_data, sample_rate)

        audio_data = self._filter_signal_by_frequencies(audio_data, sample_rate, self.frequencies)

        for start, end in chunks:
            chunk = audio_data[start:end]

            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾Ñ†ÐµÐ½Ð¾ÐºÑ‚ Ð½Ð¸Ð·ÐºÐ¸Ñ…, Ð²Ñ‹ÑÐ¾ÐºÐ¸Ñ… Ñ‡Ð°ÑÑ‚Ð¾Ñ‚ Ð² ÑÑÐ¼Ð¿Ð»Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
            dtmf_low_freq_scores = self._calculate_gortzel_scores_for_frequencies(chunk, self.low_frequencies, sample_rate)
            dtmf_high_freq_scores = self._calculate_gortzel_scores_for_frequencies(chunk, self.high_frequencies, sample_rate)

            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð¿Ð¾ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐµ
            low_freq = self._get_frequency_by_index_max_score(dtmf_low_freq_scores, self.low_frequencies)
            high_freq = self._get_frequency_by_index_max_score(dtmf_high_freq_scores, self.high_frequencies)

            decoded_numbers.append(self.frequencies_to_symbols[(low_freq, high_freq)])

            decoded_frequencies.append({
                'symbol': self.frequencies_to_symbols[(low_freq, high_freq)],
                'low_frequency': low_freq,
                'high_frequency': high_freq,
                'position_start': start,
                'position_end': end
            })

        return decoded_numbers, decoded_frequencies
    

    def _calculate_gortzel_scores_for_frequencies(
        self,
        chunk: np.ndarray,
        frequencies: List[float],
        sample_rate: int
    ) -> List[float]:
        '''Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¸Ì† Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð¼ Ð“Ñ‘Ñ€Ñ†ÐµÐ»Ñ'''
        scores = [0] * len(frequencies)
        for freq_index, freq in enumerate(frequencies):
            scores[freq_index] = self._goertzel(chunk, freq, sample_rate)
        return scores
    

    def _get_frequency_by_index_max_score(self, scores: List[float], frequencies: List[float]) -> float:
        '''ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¿Ð¾ Ð¸Ð½Ð´ÐµÐºÑÑƒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸'''
        max_score_index = scores.index(max(scores))
        return frequencies[max_score_index]
    

    def _get_chanks(self, audio_data: np.ndarray, sample_rate: int) -> List[tuple]:
        '''Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð½Ð° Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹'''
        freq_filtered_signal = self._filter_signal_by_frequencies(audio_data, sample_rate, self.frequencies)
        amp_threshold = self._calculate_amplitude_threshold(freq_filtered_signal)
        amp_filtered_signal = self._amplitude_filter(freq_filtered_signal, amp_threshold)
        window_size = int(sample_rate * self._WINDOW_SIZE_MS / 1000)
        signal_energy = self._calculate_energy(amp_filtered_signal, window_size)
        chunks = self._get_energy_intervals(signal_energy)
        return chunks
    

    def _calculate_offset(self, center_frequency: float | int) -> int:
        '''Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ¼ÐµÑ‰ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹'''
        if center_frequency >= 300 and center_frequency < 1000:
            return 20
        elif center_frequency >= 1000 and center_frequency < 3000:
            return 50
        elif center_frequency >= 3000 and center_frequency < 10000:
            return 200
        return 0


    def _butter_bandpass_filter(
        self,
        signal: np.ndarray,
        center_frequency: float,
        sample_rate: float,
        order: int = 4
    ) -> np.ndarray:
        '''ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ Ð¿Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð‘Ð°Ñ‚Ñ‚ÐµÑ€Ð²Ð¾Ñ€Ñ‚Ð° Ðº Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¼Ñƒ ÑÐ¸Ð³Ð½Ð°Ð»Ñƒ'''
        nyquist = 0.5 * sample_rate
        offset = self._calculate_offset(center_frequency)
        low = (center_frequency - offset) / nyquist
        high = (center_frequency + offset) / nyquist
        b, a = butter(order, [low, high], btype='band')
        y = lfilter(b, a, signal)
        return y


    def _filter_signal_by_frequencies(
        self,
        signal: np.ndarray,
        sample_rate: int,
        frequencies: List[float],
    ) -> np.ndarray:
        """Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÑ‚ ÑÐ¸Ð³Ð½Ð°Ð» Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð°Ð¼ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° Ð‘Ð°Ñ‚Ñ‚ÐµÑ€Ð²Ð¾Ñ€Ñ‚Ð°-Ð¿Ð¾Ð»Ð¾ÑÑ‹"""
        filtered_signal = np.sum([self._butter_bandpass_filter(signal, freq, sample_rate) for freq in frequencies], axis=0)
        return filtered_signal


    def _calculate_amplitude_threshold(self, signal: np.ndarray, multiplier: float = 1.0) -> float:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ð¿Ð¾Ñ€Ð¾Ð³Ð¾Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð°Ð¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ñ‹."""
        mean_amplitude = np.mean(np.abs(signal))
        std_amplitude = np.std(np.abs(signal))
        threshold = mean_amplitude + multiplier * std_amplitude
        return threshold


    def _amplitude_filter(self, signal: np.ndarray, threshold: float) -> np.ndarray:
        '''Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÑ‚ ÑÐ¸Ð³Ð½Ð°Ð» Ð¿Ð¾ Ð°Ð¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ðµ'''
        filtered_signal = np.where(np.abs(signal) > threshold, signal, 0)
        return filtered_signal
    
    def _calculate_energy(self, signal: np.ndarray, window_size: int) -> np.ndarray:
        '''Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ½ÐµÑ€Ð³Ð¸ÑŽ ÑÐ¸Ð³Ð½Ð°Ð»Ð°'''
        squared_signal = np.square(signal)
        energy = np.convolve(squared_signal, np.ones(window_size)/window_size, mode='valid')
        return energy
    

    def _get_energy_intervals(self, energy_values: np.ndarray) -> List[tuple]:
        """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñ‹, Ð³Ð´Ðµ ÑÐ½ÐµÑ€Ð³Ð¸Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð±Ð¾Ð»ÑŒÑˆÐµ 0."""
        intervals = []
        start_index = None

        for i, energy in enumerate(energy_values):
            if energy > 0:
                if start_index is None:
                    start_index = i
            elif start_index is not None:
                intervals.append((start_index, i - 1))
                start_index = None

        if start_index is not None:
            intervals.append((start_index, len(energy_values) - 1))

        return intervals



if __name__ == '__main__':
    dtmf = DTMF(sampling_rate=8000)

    phone_number = "1122"
    signal = dtmf.generate_dtmf_tone(phone_number)
    result = dtmf.recognize_dtmf(signal, 'wav')
    print(result)